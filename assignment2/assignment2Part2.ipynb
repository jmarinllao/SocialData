{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Random forest and weather\n",
    "The aim here is to recreate the work you did in Part 1-3 of the Week 7 lecture. I've phrased things differently relative to the exercise to make the purpose more clear.\n",
    "\n",
    "## Part 2A: Random forest binary classification.\n",
    "\n",
    "1. Using the and instructions and material from Week 7, **build a random forest classifier to distinguish between two types (you choose) of crime using on spatio-temporal (where/when) features** of data describing the two crimes. When you're done, you should be able to give the classifier a place and a time, and it should tell you which of the two types of crime happened there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\",index_col = 0,low_memory=False) \n",
    "data.drop(data.tail(5).index,inplace=True)#rimuove error alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time measures\n",
    "data[\"Hour\"]= pd.to_datetime(data[\"Time\"], format='%H:%M').dt.hour\n",
    "data[\"Date\"]= pd.to_datetime(data[\"Date\"], format='%m/%d/%Y')\n",
    "data[\"Month\"] = data['Date'].dt.month\n",
    "data[\"Day\"] = data['Date'].dt.day\n",
    "\n",
    "#crime categories analyzed\n",
    "type1=\"VEHICLE THEFT\" #influenced by weather conditions\n",
    "type2=\"FRAUD\" #not influenced\n",
    "\n",
    "#take the same amount of samples and generate dataframe containing dataset for classification\n",
    "df1=data[data[\"Category\"]==type1].sample(12000)[['Hour', 'Day', 'Month', 'PdDistrict','Category','Date']]\n",
    "df2=data[data[\"Category\"]==type2].sample(12000)[['Hour', 'Day', 'Month', 'PdDistrict','Category','Date']]\n",
    "\n",
    "df=pd.concat([df1,df2])\n",
    "\n",
    "#modify categorical values\n",
    "df['PdDistrict']=df['PdDistrict'].astype('category')\n",
    "df['PdDistrict_cat']=df['PdDistrict'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation/ test split -> 70/30\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with grid CV\n",
    "ranfor_params = {'fit__n_estimators' : range(50,200,10) , 'fit__max_depth' : range(1,6) , 'fit__max_features' : [\"sqrt\",\"log2\"]}\n",
    "\n",
    "pipe = Pipeline( [('fit',RandomForestClassifier(bootstrap=True, oob_score=True,random_state=0))] )\n",
    "\n",
    "randomForest = GridSearchCV(pipe, \n",
    "                            param_grid=ranfor_params,\n",
    "                            scoring='accuracy',\n",
    "                            cv = 5, verbose=0, n_jobs=-1).fit( np.array(df_train[['Hour', 'Day', 'Month', 'PdDistrict_cat']]), df_train['Category']).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from CV results on train set: 0.6786926236828005\n",
      "Accuracy on the test set: 0.6866583368041094\n"
     ]
    }
   ],
   "source": [
    "#print(randomForest)\n",
    "print(\"Accuracy from CV results on train set: \"+str(randomForest.score( np.array(df_train[['Hour', 'Day', 'Month', 'PdDistrict_cat']]), df_train['Category'])))\n",
    "\n",
    "#predict using best parameters\n",
    "predictions=randomForest.predict(np.array(df_test[['Hour', 'Day', 'Month', 'PdDistrict_cat']]))\n",
    "\n",
    "#compute evaluation measures\n",
    "accuracy = accuracy_score(df_test['Category'],predictions)\n",
    "print(\"Accuracy on the test set: \"+str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Explain about your choices for training/test data, features, and encoding.** (You decide how to present your results, but here are some example topics to consider: Did you balance the training data? What are the pros/cons of balancing? Do you think your model is overfitting? Did you choose to do cross-validation? Which specific features did you end up using? Why? Which features (if any) did you one-hot encode? Why ... or why not?)\n",
    "    \n",
    "      I split data in 80% train+validation and 20% for the test set. I choose to differenciate as more as possible the time varibales to have more predictors to deal with, since we have a lot of samples the curse of dimensionality is not a main issues in this problem. I choose to simply code the categorical variables, using one-hot encoding might add many misleading features, it is safer to be implemented with regularization models. I used Grid Search CV, an \"Exhaustive search over specified parameter values for an estimator.\" \\[1\\]  with that we tune the Forest and found the best parametrs. Random forests are ensemble methods known for rarely overfitting with many trees and proper parameter values\\[2\\].Then, adding CV give us more reliability in the parameter tuning generalization due to the repetited train/validation check. Thus, we can see that the C.V. training accuracy is really close to the Testing accuracy, this suggest us that we have a good generalization. On the other hand having both values above the random value we expect our model to not underfit as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Discuss the model performance. Report accuracy.**\n",
    "\n",
    "     As stated above,we see that the performance is better than random. Accuracy is the number of correct predictions made over all the predictions. We can observe a performance on the training set of 67.83% of correct classified elements and 67.67% on the test set. This means that (as expected) we perform a little worse on unseen data, but with our reliable tuning procedure we can expect a performance on more unseen data point similar to that one we had on our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2B: Info from weather features.\n",
    "\n",
    "Now add features from weather data to your random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"../datasets/weather_data.csv\",index_col = 0,low_memory=False) \n",
    "\n",
    "#merging databases\n",
    "weather[\"Hour\"]     =  pd.to_datetime(weather.index, format=\"%Y-%m-%dT%H:%M:%S.%fZ\").hour\n",
    "weather[\"Date\"]     =  pd.to_datetime(weather.index, format=\"%Y-%m-%dT%H:%M:%S.%fZ\").date\n",
    "weather[\"DateHour\"] =  weather[\"Date\"].astype(str)+\"-\"+weather[\"Hour\"].astype(str)\n",
    "df1[\"DateHour\"]     =  df1[\"Date\"].astype(str)+\"-\"+df1[\"Hour\"].astype(str)\n",
    "df2[\"DateHour\"]     =  df2[\"Date\"].astype(str)+\"-\"+df2[\"Hour\"].astype(str)\n",
    "\n",
    "df1.set_index([\"DateHour\"],inplace= True)\n",
    "df2.set_index([\"DateHour\"],inplace= True)\n",
    "weather.set_index([\"DateHour\"],inplace= True)\n",
    "\n",
    "merge1=pd.merge(df1,weather, how='inner', left_index=True, right_index=True)\n",
    "merge1=merge1.dropna()\n",
    "merge2=pd.merge(df2,weather, how='inner', left_index=True, right_index=True)\n",
    "merge2=merge2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical codifications\n",
    "df=pd.concat([merge1.sample(900),merge2.sample(900)])#due to the smaller csv bug\n",
    "\n",
    "df['weather']=df['weather'].astype('category')\n",
    "df['Weather_cat']=df['weather'].cat.codes\n",
    "\n",
    "\n",
    "df['PdDistrict']=df['PdDistrict'].astype('category')\n",
    "df['PdDistrict_cat']=df['PdDistrict'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation/ test split -> 70/30\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with grid CV\n",
    "ranfor_params = {'fit__n_estimators' : range(50,200,10) , 'fit__max_depth' : range(1,6) , 'fit__max_features' : [\"sqrt\",\"log2\"]}\n",
    "\n",
    "pipe = Pipeline( [('fit',RandomForestClassifier(bootstrap=True, oob_score=True,random_state=0))] )\n",
    "\n",
    "randomForest = GridSearchCV(pipe, \n",
    "                            param_grid=ranfor_params,\n",
    "                            scoring='accuracy',\n",
    "                            cv = 5, verbose=0, n_jobs=-1).fit(np.array(df_train[['Hour_x', 'Day', 'Month', 'PdDistrict_cat','Weather_cat','temperature']]), df_train['Category']).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from CV results on train set: 0.7180480247869868\n",
      "Accuracy on the test set: 0.6365422396856582\n"
     ]
    }
   ],
   "source": [
    "#print(randomForest)\n",
    "print(\"Accuracy from CV results on train set: \"+str(randomForest.score( np.array(df_train[['Hour_x', 'Day', 'Month', 'PdDistrict_cat','Weather_cat','temperature']]), df_train['Category'])))\n",
    "\n",
    "#predict using best parameters\n",
    "predictions=randomForest.predict(np.array(df_test[['Hour_x', 'Day', 'Month', 'PdDistrict_cat','Weather_cat','temperature']]))\n",
    "\n",
    "#compute evaluation measures\n",
    "accuracy = accuracy_score(df_test['Category'],predictions)\n",
    "print(\"Accuracy on the test set: \"+str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Report accuracy.**\n",
    "\n",
    "    On the **train set the accuracy is 0.7167449139280125**\n",
    "    \n",
    "    On the **test set the accuracy is 0.6800766283524904**\n",
    "    \n",
    "\n",
    "2. **Discuss how the model performance changes relative to the version with no weather data.**\n",
    "\n",
    "    We see a little increase in the performance, this is reasonable since we choose 2 classes that are expected to be related to the weather, however, the increasing in performance is small. This may reveal that our model is doing good(or bad) even without weather data or that data may not be so much useful for our classifictaion. We may also notice an increase in the difference between train and test performance. An high accuracy in the train set and a poor one in the test set is an indicator of overfitting. In our case, considering C.V. tuning and Leo Braiman assumptions on Random Forests \\[2\\], the difference is still reasonably small (around 3.6%) to do not expect overfitting.\n",
    "    \n",
    "\n",
    "3. **Discuss what you have learned about crime from including weather data in your model.**\n",
    "\n",
    "    Since our performance is increasing by a very small value we do not have a statistical irrefutable proof that weather is strictly related to the \"Veichle Theft\" or \"Fraud\" crimes frequenxy. Anyway, we can conclude that the weather features we have added are good predictors, beacuse our performance, in any case, have increased after adding them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\\[1\\] -> [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "\\[2\\] -> [Random Forests by LEO BREIMAN, Statistics Department, University of California, Berkeley](https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
